{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rental_Predictions_Zillow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python39164bitcityspireadspipenvfc59c3d301b9445a835af572902f875d",
      "display_name": "Python 3.9.1 64-bit ('cityspire-a-ds': pipenv)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBlKy9mmHOIu"
      },
      "source": [
        "# Zillow Dataset Cleaning - Phase 1\n",
        " Use this as a reference, you **do not** need to run these cells in Phase 1\n",
        " - [Link to the orginal dataset](https://www.zillow.com/research/data/) from Zillow's website\n",
        " - Select: `ZORI All Homes Plus Multifamily Smoothed` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do5epFXcHGDs"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m__TbrwoR5DI"
      },
      "source": [
        "# Connect to data\n",
        "FILEPATH = 'https://raw.githubusercontent.com/Lambda-School-Labs/cityspire-a-ds/main/notebooks/Rental_Data/Zillow_Datasets/Zillow_Original.csv'\n",
        "zillow_original = pd.read_csv(FILEPATH)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F09oXa5kXDaN"
      },
      "source": [
        "# Function to clean up the dataset + yearly average columns\n",
        "\n",
        "def zillow_cleaner(df):\n",
        "  ''' A function to convert a dataset from Zillow into something more useable \n",
        "  for a predictive model.\n",
        "  '''\n",
        "\n",
        "  # Drop columns\n",
        "  df = df.drop(['RegionID', 'RegionName', 'SizeRank'], axis=1)\n",
        "\n",
        "  # Change column name\n",
        "  df = df.rename(columns={\"MsaName\": \"City_State\"})\n",
        "\n",
        "  # Creating yearly average columns\n",
        "  # 2014 averages\n",
        "  fourteen_columns = list(df)[1:13]\n",
        "  df.insert(13, '2014_Average',\n",
        "                    df[fourteen_columns].mean(axis=1), True)\n",
        "  # 2015 averages\n",
        "  fifteen_columns = list(df)[14:26]\n",
        "  df.insert(26, '2015_Average',\n",
        "                    df[fifteen_columns].mean(axis=1), True)\n",
        "  # 2016 averages\n",
        "  sixteen_columns = list(df)[27:39]\n",
        "  df.insert(39, '2016_Average',\n",
        "                    df[sixteen_columns].mean(axis=1), True)\n",
        "  # 2017 averages\n",
        "  seventeen_columns = list(df)[40:52]\n",
        "  df.insert(52, '2017_Average',\n",
        "                    df[seventeen_columns].mean(axis=1), True)\n",
        "  # 2018 averages\n",
        "  eightteen_columns = list(df)[53:65]\n",
        "  df.insert(65, '2018_Average',\n",
        "                    df[eightteen_columns].mean(axis=1), True)\n",
        "  # 2019 averages\n",
        "  nineteen_columns = list(df)[66:78]\n",
        "  df.insert(78, '2019_Average',\n",
        "                    df[nineteen_columns].mean(axis=1), True)\n",
        "  # 2020 averaes\n",
        "  twentytwenty_columns = list(df)[79:91]\n",
        "  df.insert(91, '2020_Average',\n",
        "                    df[twentytwenty_columns].mean(axis=1), True)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bsQO99SXTLy"
      },
      "source": [
        "# Run cleaning function\n",
        "zillow_original = zillow_cleaner(zillow_original)\n",
        "\n",
        "# Check it out\n",
        "print(zillow_original.shape)\n",
        "zillow_original.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2608, 93)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     City_State  2014-01  2014-02  2014-03  2014-04  2014-05  2014-06  \\\n",
              "0  New York, NY   2941.0   2899.0   2913.0   2978.0   2960.0   2954.0   \n",
              "1   Chicago, IL   1419.0   1400.0   1417.0   1445.0   1457.0   1488.0   \n",
              "2  New York, NY   3131.0   3133.0   3126.0   3169.0   3214.0   3284.0   \n",
              "3   Houston, TX   1760.0   1676.0   1741.0   1732.0   1754.0   1768.0   \n",
              "4   Chicago, IL   1615.0   1623.0   1633.0   1658.0   1676.0   1693.0   \n",
              "\n",
              "   2014-07  2014-08  2014-09  ...  2020-05  2020-06  2020-07  2020-08  \\\n",
              "0   2997.0   3010.0   3016.0  ...   3147.0   3075.0   3041.0   2953.0   \n",
              "1   1489.0   1486.0   1466.0  ...   1675.0   1668.0   1636.0   1628.0   \n",
              "2   3269.0   3267.0   3261.0  ...   3349.0   3303.0   3192.0   3137.0   \n",
              "3   1772.0   1776.0   1787.0  ...   1749.0   1754.0   1764.0   1772.0   \n",
              "4   1718.0   1711.0   1716.0  ...   1954.0   1936.0   1920.0   1878.0   \n",
              "\n",
              "   2020-09  2020-10  2020-11  2020-12  2020_Average  2021-01  \n",
              "0   2909.0   2768.0   2726.0   2703.0   3027.000000   2775.0  \n",
              "1   1593.0   1575.0   1540.0   1545.0   1626.333333   1571.0  \n",
              "2   3038.0   2975.0   2915.0   2851.0   3201.833333   2872.0  \n",
              "3   1778.0   1764.0   1789.0   1798.0   1765.083333   1795.0  \n",
              "4   1860.0   1815.0   1753.0   1743.0   1880.750000   1721.0  \n",
              "\n",
              "[5 rows x 93 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City_State</th>\n      <th>2014-01</th>\n      <th>2014-02</th>\n      <th>2014-03</th>\n      <th>2014-04</th>\n      <th>2014-05</th>\n      <th>2014-06</th>\n      <th>2014-07</th>\n      <th>2014-08</th>\n      <th>2014-09</th>\n      <th>...</th>\n      <th>2020-05</th>\n      <th>2020-06</th>\n      <th>2020-07</th>\n      <th>2020-08</th>\n      <th>2020-09</th>\n      <th>2020-10</th>\n      <th>2020-11</th>\n      <th>2020-12</th>\n      <th>2020_Average</th>\n      <th>2021-01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New York, NY</td>\n      <td>2941.0</td>\n      <td>2899.0</td>\n      <td>2913.0</td>\n      <td>2978.0</td>\n      <td>2960.0</td>\n      <td>2954.0</td>\n      <td>2997.0</td>\n      <td>3010.0</td>\n      <td>3016.0</td>\n      <td>...</td>\n      <td>3147.0</td>\n      <td>3075.0</td>\n      <td>3041.0</td>\n      <td>2953.0</td>\n      <td>2909.0</td>\n      <td>2768.0</td>\n      <td>2726.0</td>\n      <td>2703.0</td>\n      <td>3027.000000</td>\n      <td>2775.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chicago, IL</td>\n      <td>1419.0</td>\n      <td>1400.0</td>\n      <td>1417.0</td>\n      <td>1445.0</td>\n      <td>1457.0</td>\n      <td>1488.0</td>\n      <td>1489.0</td>\n      <td>1486.0</td>\n      <td>1466.0</td>\n      <td>...</td>\n      <td>1675.0</td>\n      <td>1668.0</td>\n      <td>1636.0</td>\n      <td>1628.0</td>\n      <td>1593.0</td>\n      <td>1575.0</td>\n      <td>1540.0</td>\n      <td>1545.0</td>\n      <td>1626.333333</td>\n      <td>1571.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>New York, NY</td>\n      <td>3131.0</td>\n      <td>3133.0</td>\n      <td>3126.0</td>\n      <td>3169.0</td>\n      <td>3214.0</td>\n      <td>3284.0</td>\n      <td>3269.0</td>\n      <td>3267.0</td>\n      <td>3261.0</td>\n      <td>...</td>\n      <td>3349.0</td>\n      <td>3303.0</td>\n      <td>3192.0</td>\n      <td>3137.0</td>\n      <td>3038.0</td>\n      <td>2975.0</td>\n      <td>2915.0</td>\n      <td>2851.0</td>\n      <td>3201.833333</td>\n      <td>2872.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Houston, TX</td>\n      <td>1760.0</td>\n      <td>1676.0</td>\n      <td>1741.0</td>\n      <td>1732.0</td>\n      <td>1754.0</td>\n      <td>1768.0</td>\n      <td>1772.0</td>\n      <td>1776.0</td>\n      <td>1787.0</td>\n      <td>...</td>\n      <td>1749.0</td>\n      <td>1754.0</td>\n      <td>1764.0</td>\n      <td>1772.0</td>\n      <td>1778.0</td>\n      <td>1764.0</td>\n      <td>1789.0</td>\n      <td>1798.0</td>\n      <td>1765.083333</td>\n      <td>1795.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Chicago, IL</td>\n      <td>1615.0</td>\n      <td>1623.0</td>\n      <td>1633.0</td>\n      <td>1658.0</td>\n      <td>1676.0</td>\n      <td>1693.0</td>\n      <td>1718.0</td>\n      <td>1711.0</td>\n      <td>1716.0</td>\n      <td>...</td>\n      <td>1954.0</td>\n      <td>1936.0</td>\n      <td>1920.0</td>\n      <td>1878.0</td>\n      <td>1860.0</td>\n      <td>1815.0</td>\n      <td>1753.0</td>\n      <td>1743.0</td>\n      <td>1880.750000</td>\n      <td>1721.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 93 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1TsKZOxYIN0"
      },
      "source": [
        "[GeekforGeeks](https://www.geeksforgeeks.org/python-pandas-dataframe-interpolate) - Interpolate Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRKIY-7vXb8N"
      },
      "source": [
        "# Deal with NaN with interpolate, a way to estimate instead of dropping\n",
        "zillow_original.interpolate(method='linear', axis=0, inplace=True, limit_direction='both', limit_area='inside', downcast=None)\n",
        "\n",
        "# Inspect\n",
        "zillow_original.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2608 entries, 0 to 2607\nData columns (total 93 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   City_State    2608 non-null   object \n 1   2014-01       2608 non-null   float64\n 2   2014-02       2606 non-null   float64\n 3   2014-03       2607 non-null   float64\n 4   2014-04       2608 non-null   float64\n 5   2014-05       2604 non-null   float64\n 6   2014-06       2608 non-null   float64\n 7   2014-07       2606 non-null   float64\n 8   2014-08       2608 non-null   float64\n 9   2014-09       2608 non-null   float64\n 10  2014-10       2608 non-null   float64\n 11  2014-11       2605 non-null   float64\n 12  2014-12       2604 non-null   float64\n 13  2014_Average  2608 non-null   float64\n 14  2015-01       2607 non-null   float64\n 15  2015-02       2607 non-null   float64\n 16  2015-03       2607 non-null   float64\n 17  2015-04       2608 non-null   float64\n 18  2015-05       2608 non-null   float64\n 19  2015-06       2608 non-null   float64\n 20  2015-07       2608 non-null   float64\n 21  2015-08       2608 non-null   float64\n 22  2015-09       2608 non-null   float64\n 23  2015-10       2608 non-null   float64\n 24  2015-11       2607 non-null   float64\n 25  2015-12       2607 non-null   float64\n 26  2015_Average  2608 non-null   float64\n 27  2016-01       2604 non-null   float64\n 28  2016-02       2608 non-null   float64\n 29  2016-03       2607 non-null   float64\n 30  2016-04       2608 non-null   float64\n 31  2016-05       2608 non-null   float64\n 32  2016-06       2608 non-null   float64\n 33  2016-07       2608 non-null   float64\n 34  2016-08       2608 non-null   float64\n 35  2016-09       2608 non-null   float64\n 36  2016-10       2608 non-null   float64\n 37  2016-11       2608 non-null   float64\n 38  2016-12       2608 non-null   float64\n 39  2016_Average  2608 non-null   float64\n 40  2017-01       2607 non-null   float64\n 41  2017-02       2608 non-null   float64\n 42  2017-03       2608 non-null   float64\n 43  2017-04       2608 non-null   float64\n 44  2017-05       2608 non-null   float64\n 45  2017-06       2608 non-null   float64\n 46  2017-07       2608 non-null   float64\n 47  2017-08       2608 non-null   float64\n 48  2017-09       2608 non-null   float64\n 49  2017-10       2608 non-null   float64\n 50  2017-11       2608 non-null   float64\n 51  2017-12       2608 non-null   float64\n 52  2017_Average  2608 non-null   float64\n 53  2018-01       2608 non-null   float64\n 54  2018-02       2608 non-null   float64\n 55  2018-03       2608 non-null   float64\n 56  2018-04       2607 non-null   float64\n 57  2018-05       2607 non-null   float64\n 58  2018-06       2608 non-null   float64\n 59  2018-07       2608 non-null   float64\n 60  2018-08       2608 non-null   float64\n 61  2018-09       2608 non-null   float64\n 62  2018-10       2608 non-null   float64\n 63  2018-11       2607 non-null   float64\n 64  2018-12       2608 non-null   float64\n 65  2018_Average  2608 non-null   float64\n 66  2019-01       2608 non-null   float64\n 67  2019-02       2608 non-null   float64\n 68  2019-03       2608 non-null   float64\n 69  2019-04       2608 non-null   float64\n 70  2019-05       2608 non-null   float64\n 71  2019-06       2608 non-null   float64\n 72  2019-07       2608 non-null   float64\n 73  2019-08       2608 non-null   float64\n 74  2019-09       2607 non-null   float64\n 75  2019-10       2608 non-null   float64\n 76  2019-11       2607 non-null   float64\n 77  2019-12       2607 non-null   float64\n 78  2019_Average  2608 non-null   float64\n 79  2020-01       2608 non-null   float64\n 80  2020-02       2608 non-null   float64\n 81  2020-03       2608 non-null   float64\n 82  2020-04       2608 non-null   float64\n 83  2020-05       2608 non-null   float64\n 84  2020-06       2608 non-null   float64\n 85  2020-07       2608 non-null   float64\n 86  2020-08       2608 non-null   float64\n 87  2020-09       2608 non-null   float64\n 88  2020-10       2608 non-null   float64\n 89  2020-11       2608 non-null   float64\n 90  2020-12       2608 non-null   float64\n 91  2020_Average  2608 non-null   float64\n 92  2021-01       2608 non-null   float64\ndtypes: float64(92), object(1)\nmemory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS2HrRL8Y7YK"
      },
      "source": [
        "Oddly not all of the NaNs were converted to a numerical value based on neighbors. Assumption is that if there are multiple NaNs in sequence the `interpolate()` function has a hard time defining a value.\n",
        "\n",
        "There were only a hand full of these, so they were corrected manually. Taking the average of the nearest four neighbors, a numerical value was given for the NaN."
      ]
    },
    {
      "source": [
        "# Zillow Dataset Cleaning - Phase 2\n",
        "- The dataset below has the NaNs correctly manually"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to data\n",
        "FILEPATH = 'https://raw.githubusercontent.com/Lambda-School-Labs/cityspire-a-ds/main/notebooks/Rental_Data/Zillow_Datasets/Corrected_Zillow.csv'\n",
        "zillow_corrected = pd.read_csv(FILEPATH)"
      ]
    },
    {
      "source": [
        "## Step 1: break apart the state from the city list\n",
        "\n",
        "This dataset contains multiple cities that are in the same observations. For example *Dallas-Fort Worth*\n",
        "\n",
        "Thus `explode` is used to seperate the observation into two rows. Giving the model more data to work with.\n",
        "\n",
        "In order to use this function, the `City/State` columns has to be two seperate columns\n",
        "\n",
        "[Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html) - *Explode Function*"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split 'city/state' so the cities can be exploded\n",
        "zillow_corrected[['City', 'State']] = zillow_corrected['City_State'].str.split(', ', expand=True)\n",
        " \n",
        "# This is being dropped - changing the name later\n",
        "zillow_corrected = zillow_corrected.drop('City_State', axis=1)\n",
        " \n",
        "# Explode the rows with multiple cities in an observation\n",
        "zillow_corrected['City'] = zillow_corrected['City'].str.split('-')\n",
        "zillow_corrected = zillow_corrected.explode('City')"
      ]
    },
    {
      "source": [
        "## Step 2: Convert abbreviated state names into full names\n",
        "- [GitHub](https://gist.githubusercontent.com/rogerallen/1583593/raw/0fffdee6149ab1d993dffa51b1fa9aa466704e18/us_state_abbrev.py) - US State dictionary used below"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "us_state_abbrev = {\n",
        "    'Alabama': 'AL', 'Alaska': 'AK', 'American Samoa': 'AS', 'Arizona': 'AZ',\n",
        "    'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT',\n",
        "    'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL',\n",
        "    'Georgia': 'GA', 'Guam': 'GU', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
        "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
        "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
        "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n",
        "    'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE',\n",
        "    'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
        "    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n",
        "    'North Dakota': 'ND', 'Northern Mariana Islands':'MP', 'Ohio': 'OH',\n",
        "    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Puerto Rico': 'PR',\n",
        "    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
        "    'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
        "    'Virgin Islands': 'VI', 'Virginia': 'VA', 'Washington': 'WA',\n",
        "    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
        "}\n",
        " \n",
        "# Flip the dictonary, need the state codes as keys\n",
        "us_state_abbrev = {value: key for key, value in us_state_abbrev.items()}\n",
        " \n",
        "# Convert the state codes to state names\n",
        "zillow_corrected['State'] = zillow_corrected['State'].map(us_state_abbrev)\n"
      ]
    },
    {
      "source": [
        "## Step 3: Re-combine the city and state information\n",
        "\n",
        "- New column will be `City_State`"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine and insert at the front of the dataframe\n",
        "zillow_corrected.insert(loc=0, column='City_State', \n",
        "                        value=(zillow_corrected['City'] + ', ' + \n",
        "                               zillow_corrected['State']))\n",
        " \n",
        "# Delete our temp columns\n",
        "zillow_corrected = zillow_corrected.drop(['City', 'State'], axis=1)"
      ]
    },
    {
      "source": [
        "## Step 4: Handle duplicate city-state entries\n",
        "\n",
        "The original dataset has multiple observations for the same city. The reason behind this is due to a city having multiple zipcodes, thus data was collected by zipcode.\n",
        "\n",
        "Grouping these observations together into one row is ideal. Taking the average of the combined cities zipcodes helps keep the most data.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average accross the city \n",
        "zillow_corrected = zillow_corrected.groupby('City_State').mean()\n",
        "\n",
        "# Round to 2 decimal places\n",
        "zillow_corrected = zillow_corrected.round(decimals=2)"
      ]
    },
    {
      "source": [
        "# Modeling\n",
        "\n",
        "## Step 1: Separating Columns\n",
        "\n",
        "The dataset contains columns of months and columns for yearly averages. For the predictive model, the monthly columns will be used. The yearly averages will be used later on.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the averages columns for later\n",
        "zillow_year_average = zillow_corrected[[col for col in zillow_corrected if 'Average' in col]]\n",
        "\n",
        "# These non-average columns are for predicting\n",
        "zillow_corrected = zillow_corrected[[col for col in zillow_corrected if 'Average' not in col]]"
      ]
    },
    {
      "source": [
        "## Step 2: Create the Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'make_pipeline' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-307734882c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define algorithms for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model = make_pipeline(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "X_train = zillow_corrected.iloc[:, :-1]   # Every month but the last month\n",
        "y_test = zillow_corrected.iloc[:, -1:]    # Only the last month\n",
        "\n",
        "# Define algorithms for the model\n",
        "model = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    StandardScaler(),\n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train, y_test)"
      ]
    },
    {
      "source": [
        "## Step 3: Check Metrics"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New dataframe to display metrics\n",
        "test_results = pd.DataFrame(index=zillow_corrected.index)\n",
        "\n",
        "# Original results\n",
        "test_results['original'] = y_test\n",
        "\n",
        "# Predicted results from model - rounded\n",
        "test_results['predicted'] = np.round(model.predict(X_train), 2)\n",
        "\n",
        "# Take the difference from predicted vs original\n",
        "test_results['differnce'] = test_results['predicted'] - test_results['original']\n",
        "\n",
        "# Calculate the percent of error\n",
        "test_results['percent_error'] = test_results['differnce'].abs() / test_results['original'] * 100\n",
        "\n",
        "test_results"
      ]
    },
    {
      "source": [
        "# Phase 3 - Get Future Predictions\n",
        "\n",
        "## Step 1: Create a function to help recurse over many months of data\n",
        "\n",
        "This function serves as a means to repeatedly run the model to extend the dataset as far as needed. It will accept a dataframe, model, and the number of months to generate."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Functon to extrapolate from dataset (recursive)\n",
        "def extrapolate(df, model, n_month_to_predict, remove_negatives=False):\n",
        "  ''' Takes a dataframe, machine learning model and an integer to represent the\n",
        "  number of months to be predicted.\n",
        "  '''\n",
        "  \n",
        "  # If we are less than 1, just return the last column, we're done\n",
        "  if n_month_to_predict < 1:\n",
        "    return df.iloc[:, -1:]\n",
        "   \n",
        "  # How many columns does the model use?\n",
        "  n_columns = max([s.rank_ for n, s in model.steps if n == 'linearregression'])\n",
        "   \n",
        "  # Then make the prediction for this month\n",
        "  '''\n",
        "    ':'   -> all rows\n",
        "    '-n'  -> count form the back 'n' places\n",
        "    'n:'  -> start at 'n' and go all the way to the end\n",
        "    '-n:' -> start by counting from the end 'n' places,\n",
        "               then take from that position to the end\n",
        "  '''\n",
        "  df[len(df.columns)] = model.predict(df.iloc[:, -n_columns:])\n",
        "\n",
        "  # It makes sense for the data, remove negative predictions\n",
        "  # Set them to zero\n",
        "  if remove_negatives:\n",
        "    df[df < 0] = 0\n",
        "\n",
        "  # Then ask for the next month\n",
        "  return extrapolate(df, model, n_month_to_predict - 1, remove_negatives)\n"
      ]
    },
    {
      "source": [
        "## Step 2: Generate Data\n",
        "\n",
        "- 10 years (120 months) of generated data."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a copy of the dataframe\n",
        "zillow_corrected_pred = zillow_corrected.copy()\n",
        "\n",
        "# Extrapolate will tack on \"new data\" to the dataframe\n",
        "# zillow_corrected_pred will have all of the predictive data in it\n",
        "extrapolate(zillow_corrected_pred, model, 120, True)\n",
        "\n",
        "# Isolate all the predictive data\n",
        "zillow_corrected_pred = zillow_corrected_pred.iloc[:, len(zillow_corrected.columns):]"
      ]
    },
    {
      "source": [
        "Currently the data frame has each month as an integer (84, 85, 86 etc.). These column months need to be changed into an easier to read `YYYY-MM` format. Also each 12 months needs to be averaged out for that year.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Yearly averages function\n",
        "def average_years(df, years):\n",
        "  ''' Averages the data for specific years and returns as new dataframe\n",
        "  '''\n",
        "\n",
        "  yearly_df = pd.DataFrame(index=df.index)\n",
        "  for y in years:\n",
        "    yearly_df[y + '_Average'] = np.round(df[[col for col in df if y in col]].mean(axis=1), 2)\n",
        "    \n",
        "  return yearly_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up columns as dictionary\n",
        "new_columns = dict()\n",
        "\n",
        "# Find the first year\n",
        "first_year = min(list({int(col[:4]) for col in zillow_corrected.columns}))\n",
        "\n",
        "# Make new associations from integers to `YYYY-MM` formatted strings\n",
        "for m in zillow_corrected_pred.columns:\n",
        "   new_columns[m] = str(first_year + int(m / 12)) + '-' + str((m % 12) + 1).zfill(2)\n",
        "\n",
        "# Replace the column names\n",
        "zillow_pred = zillow_corrected_pred.rename(columns=new_columns)\n",
        "\n",
        "# Find all the years in prediction dataset\n",
        "years = list({col[:4] for col in zillow_pred.columns})\n",
        "years.sort()\n",
        "\n",
        "# Save the averages in a new dataframe\n",
        "zillow_year_pred = average_years(zillow_pred, years)"
      ]
    },
    {
      "source": [
        "## Step 3: Export\n",
        "\n",
        "The data is organized by defualt to have every row be a unique `city_state` and every column to have a specific `year-month`. This won't allow the table to expand easily if a user requests a brand-new year-month. Rearanging the data to have a column for place, time, and price will allow for faster lookups. We can also do this for year averages."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export function \n",
        "def export_format(df):\n",
        "  ''' Make the data into an easily suported shape for the server '''\n",
        "\n",
        "  # New dataframe\n",
        "  exportdf = pd.DataFrame(columns = ['City_State', 'Year_Month', 'Price'])\n",
        "   \n",
        "  # Break up the original dataframe by rows, and keep track of the index (i)\n",
        "  # i is the city_state string\n",
        "  for i, row in df.iterrows():\n",
        "    # Go through each column of each row\n",
        "    for col in df.columns:\n",
        "      # Add a new record to the bottom of the new dataframe\n",
        "      exportdf.loc[len(exportdf.index)] = [i, col, row[col]]\n",
        "\n",
        "  return exportdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the historic information we used for the modeling\n",
        "historic = export_format(zillow_corrected)\n",
        "historic['Type'] = 'Historic'\n",
        "\n",
        "# Add the averages that were calculated\n",
        "historic_avg = export_format(zillow_year_average)\n",
        "historic_avg['Type'] = 'Calculated'\n",
        "export = historic.append(historic_avg)\n",
        "\n",
        "# Convert the predicted information\n",
        "pred = export_format(zillow_pred)\n",
        "pred = pred.append(export_format(zillow_year_pred))\n",
        "pred['Type'] = 'Predicted'\n",
        "\n",
        "# Mash it all together\n",
        "export = export.append(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check out export version\n",
        "export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check out yearly version\n",
        "zillow_year_pred"
      ]
    }
  ]
}